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



litgpt finetune_lora \
    checkpoints/TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
    --data JSON \
    --data.json_path train.json \
    --data.val_split_fraction 0.1 \
    --out_dir finetuned-tinyllama \
    --train.max_steps 100 \
    --train.save_interval 50 \
    --eval.interval 25

litgpt merge_lora \
  --base_model checkpoints/TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
  --lora_path finetuned-tinyllama \
  --out_dir finetuned-tinyllama/merged \
  --precision fp32

    